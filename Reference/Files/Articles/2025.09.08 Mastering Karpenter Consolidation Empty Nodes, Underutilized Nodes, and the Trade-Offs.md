#karpenter #medium #nodes #consolidation #autoscaling 

![](https://miro.medium.com/v2/resize:fit:1050/1*JjfK05EqzAWnJXFDQGdP9A.png)

Karpenter is slowly becoming the default Kubernetes autoscaler for EKS and beyond. Itâ€™s fast, flexible and smarter than the old Cluster Autoscaler. But once you move past the default setup, one of the biggest questions teams hit is:

ğŸ‘‰Â **Should I consolidate only empty nodes, or also underutilized nodes?**

On paper, consolidating underutilized nodes promises big savings. In practice, it can introduce churn, noisy neighbors, and service disruption if youâ€™re not careful. We have been using Karpenter for years, while still on the way to tune different parameters wishing to achieve a better balance between SLO and cost. Here are what I have learned.

## Empty Node Consolidation: The Safe Default

By default, Karpenter is conservative. It will consolidate onlyÂ **empty nodes**Â â€” nodes with zero non-daemonset pods. Terminating those nodes is risk-free: nothing needs to be evicted, workloads arenâ€™t disrupted, and you save on idle capacity.

This is a great starting point: low savings, but rock-solid stability.

## Underutilized Node Consolidation: More Savings, More Risk

EnablingÂ **underutilized consolidation**Â tells Karpenter to look for nodes thatÂ _could_Â be drained, because their workloads can all fit elsewhere. Important to notice here: When you setÂ `consolidationPolicy: WhenUnderutilized`,Â **Karpenter does not look at simple node-level utilization metrics**Â (like CPU% or memory%). Instead it sees if the node workload can be rebalanced somewhere else while keeps the workload constraints.

Enabling underutilized consolidation unlocks cost savings but introduces new concerns:

- **Pod Evictions**Â â€” pods get restarted on different nodes. For stateless applications this could be fine; for stateful or long-running pods, it will cause downtime; And if you are running stateless CI/CD, this is not fine, since your jobs will be terminated.
- **Churn / Thrash**Â â€” if workloads are bursty, nodes may be consolidated and then re-created shortly after.
- **Blast Radius**Â â€” the bigger the node, the bigger the impact. Consolidating for example a 24xlarge nodes may evict hundreds of pods at once.
- **Noisy Neighbors**Â â€” denser packing increases the chance that one workloadâ€™s spikes affect its neighbors.

## The Churn (Thrash) Problem

Consolidation decisions are opportunistic: if pods can fit elsewhere, Karpenter acts. But what if traffic surges 10 minutes later?

You get the dreadedÂ **consolidation thrash**:

1. Node is marked underutilized.
2. Pods are evicted and rescheduled elsewhere(depends on pods nature, it could be simply evicted without recreation for some CI/CD workloads).
3. A load spike forces a new node to be created.
4. Workload drops again â†’ back to underutilized.

This cycle wastes instance startup time, increases pod restarts, interrupt CI/CD jobs and can cancel out your cost savings.

### ğŸ’¸ Impact on Cost Savings

Churn doesnâ€™t just disrupt workloads â€” it undermines the very efficiency gains consolidation is meant to deliver:

- **Overlap costs**: During scale-out, you pay for both the terminating node and the new node booting.
- **Wasted partial lifetimes**: EC2 bills per second, but nodes consolidated after only minutes of uptime waste most of their potential usage. On large instances (like 24xlarge), this can be very expensive.
- **Overprovisioning buffers**: To mask instability from frequent restarts, teams often run extra buffers, which eats into savings.

Instead of reducing spend, excessive churn can flatten or even reverse your cost optimization curve.

### ğŸŒ Impact on IP Exhaustion

Churn also stresses the clusterâ€™s networking resources:

- **Each new node reserves ENIs and IP blocks**, even if only a few pods run on it initially.
- **IPs are only released when the node terminates**, not when pods are evicted. If consolidation/expiration happens often, IPs bounce between ENIs and subnets.
- With small node sizes, the effect is amplified: more nodes â†’ more ENIs â†’ more reserved IPs.
- In small subnets (`/24`Â orÂ `/25`), this can lead toÂ **temporary IP exhaustion**, blocking new pod scheduling until addresses free up.

In other words, consolidation churn can trade one bottleneck (compute) for another (networking).

### âš–ï¸ Mitigating Churn

- UseÂ `**consolidateAfter**`Â to wait out short-term fluctuations and to delay before a node is considered for consolidation. This tells Karpenter to wait 20 minutes before draining an underutilized node, filtering out short-term fluctuations.

disruption:  
  consolidationPolicy: WhenEmptyOrUnderutilized  
  consolidateAfter: 20m

- TuneÂ **NodePool disruption budgets**Â to limit simultaneous evictions. More details afterwards.
- Right-size subnets and enableÂ **prefix delegation**Â in the VPC CNI to reduce wasted IPs.
- FavorÂ **larger nodes**Â for IP efficiency, but balance against blast radius risk.

## Blast Radius on Big Nodes

When every node is aÂ **24xlarge**, consolidation gets dangerous.

- Evicting one node = evicting potentiallyÂ **hundreds of pods**.
- If those pods belong to the same service, you risk dropping too many replicas at once.
- Even with stateless apps, that can mean latency spikes or 5xx errors.

**Best practice:**Â either mix in smaller instance sizes for finer granularity, or use anti-affinity / topology spread constraints to keep replicas spread across nodes.

## Noisy Neighbors: Where Limits Donâ€™t Match Requests

Hereâ€™s another hidden cost of aggressive consolidation:Â **noisy neighbors**.

- The Kubernetes scheduler (EKS included) places pods based onÂ **resource requests**, not limits.
- At runtime, pods can burst up to theirÂ **limits**.
- If requests are low and limits are high, Karpenter may pack many pods onto one node.
- When multiple pods burst at once, they compete â€” causing CPU throttling, memory OOMs, and performance spikes.

This effect is amplified onÂ **large nodes**Â with lots of co-located pods.

**Mitigations:**

- Set sensible requests and limits (donâ€™t leave them unset).
- Use Guaranteed QoS for critical pods (requests = limits).
- Spread replicas across nodes with topology spread constraints.

## Controlling Consolidation with NodePool Disruption Budgets

Sometimes, the right strategy isnâ€™t purely technical â€” itâ€™s organizational. What if your business requiresÂ **zero disruption**Â during the day, but youâ€™re willing to consolidate aggressively at night?

Karpenterâ€™sÂ `NodePool`Â disruption budgets (`spec.disruption.budgets`) let you cap how many nodes can be disrupted at once, and for which reasons. While you can't set time windows directly within theÂ `NodePool`Â spec, you can automate it.

### The Automation Trick: Time-Based Budgeting

The key is to use an external automation tool to dynamically update yourÂ `NodePool`Â configuration.

1. **Define Your Budgets:**Â Create two distinct budget configurations for yourÂ `NodePool`.  
    **Daytime Budget:**Â SetÂ `consolidation: 0`. This will effectively pause all consolidation activity during your business hours, ensuring maximum stability.  
    **Nighttime Budget:**Â SetÂ `consolidation`Â to a non-zero value, likeÂ `consolidation: 10%`. This tells Karpenter it's okay to consolidate up to 10% of your nodes at a time, allowing it to perform its cost-saving magic overnight.
2. **Automate the Switch:**Â Use a Kubernetes-native automation tool to apply these changes on a schedule.

- **A**Â `**CronJob**`**:**Â A simpleÂ `CronJob`Â can be configured to run twice a day. The job would useÂ `kubectl patch`Â to apply the desiredÂ `consolidation`Â budget to yourÂ `NodePool`Â at the beginning and end of your business hours.
- **GitOps (ArgoCD or Flux):**Â A more robust solution involves GitOps. You can maintain two versions of yourÂ `NodePool`Â manifest (e.g.,Â `nodepool-day.yaml`Â andÂ `nodepool-night.yaml`). Your CI/CD pipeline or a dedicated GitOps controller can be configured to "sync" the appropriate manifest at specific times. This approach is more resilient and auditable.

This simple trick gives you business-hour safety without giving up cost savings entirely.

### âš ï¸ Important Caveats to Consider

While this approach is effective, itâ€™s not without its constraints. For this strategy to work seamlessly, you must also consider:

1. **Consolidation is Not Instant:**Â When the budget is opened at night, Karpenter will begin the consolidation process. However, it will take time to identify, cordon, drain, and terminate nodes. Depending on the number of nodes and theÂ `terminationGracePeriod`Â of your pods, this process could take a while.
2. **Node Expiration Bypasses the Budget:**Â Remember that Karpenterâ€™sÂ **node expiration**Â logic (`spec.disruption.expireAfter`) is completely separate from theÂ `consolidation`Â budget. If a node reaches its expiration time, Karpenter will disrupt itÂ **regardless**Â of yourÂ `consolidation`Â budget. This is a critical safety feature to ensure nodes are regularly recycled for maintenance.
3. **No**Â `**SIGTERM**`Â **During the Day:**Â If aÂ `0`Â budget is in place, Karpenter's eviction requests are immediately rejected by the Kubernetes API server. This means pods on underutilized nodes will never receive aÂ `SIGTERM`Â from Karpenter, as the eviction process is not even allowed to begin. The pods will remain in aÂ `Running`Â state, and the node will remain active.
4. **IP Exhaustion Can Still Occur:**Â While your automated system works, an unexpected spike in demand during the day could still cause your cluster to provision a large number of nodes. Since Karpenter canâ€™t consolidate them with aÂ `0`Â budget, they will remain in the cluster, potentially leading to IP exhaustion or node bloat if the demand drops.

By understanding these nuances, you can use Karpenterâ€™s disruption budgets to achieve a powerful balance between application stability and operational efficiency.

## ExpireAfter vs ConsolidateAfter: Lifecycle vs Opportunistic Recycling

Karpenter uses two distinct mechanisms for node disruption, balancing the long-term health of your cluster with immediate cost optimization.

### `spec.disruption.expireAfter`Â â†’ The Proactive Lifecyle Manager

This setting defines a maximum lifespan for a node, likeÂ `720h`. When a node reaches this age, it's automatically replaced, regardless of its utilization. The purpose is to enforce regular node recycling for security and maintenance, ensuring nodes are always running the latest AMI and patches. This is aÂ **forceful disruption**Â that bypasses most disruption budgets.

### `spec.disruption.consolidationPolicy`Â â†’ The Opportunistic Cost Saver

This setting is about saving money in real time. It identifies underutilized nodes and attempts to remove them. This is aÂ **graceful disruption**Â that strictly respects yourÂ `NodePool`Â disruption budgets. To prevent churn, you can use:

- `**spec.disruption.consolidateAfter**`: A grace period that starts when a node becomes a candidate for consolidation. If new pods are scheduled on the node, this timerÂ **resets**, ensuring the node isn't disrupted if it's still needed.

For graceful disruptions like consolidation, Karpenter proactively requests aÂ **new replacement node**Â and waits for it to become readyÂ **before**Â it begins to drain pods from the old node. This â€œpre-spinâ€ ensures that new capacity is available and healthy, minimizing service interruption and making the consolidation process seamless.

## Karpenter and Your SLOs

Karpenterâ€™s consolidation is an act of voluntary disruption that can directly impact your serviceâ€™s reliability. The key is to balance its cost-saving benefits with your Service Level Objectives (SLOs).

- **Availability:**Â When Karpenter drains pods to consolidate, it can cause a brief period of unavailability that affects your serviceâ€™s availability SLI.Â **Pod Disruption Budgets (PDBs)**Â are your shield here; they prevent Karpenter from violating your minimum replica count.
- **Latency:**Â The process of moving pods can introduce latency spikes due toÂ **â€œcold startsâ€**Â on new nodes or increased CPU contention as pods are packed more tightly.
- **The Compromise:**
- **Aggressive consolidation**Â (`WhenUnderutilized`) is great for saving money but comes with a higher risk of disrupting your SLOs.
- **Conservative consolidation**Â (`WhenEmpty`) is safer for critical services but sacrifices some cost efficiency.

## Soâ€¦ Should You Enable Underutilized Consolidation?

It depends.

- **Stateless, bursty workloads, big nodes?**Â â†’ Stick with empty-node consolidation. Savings from underutilized may not justify the churn and blast radius.
- **Stateless, stable workloads, smaller nodes, tuned disruption budgets?**Â â†’ Underutilized consolidation can be a big cost win.
- **Mixed workloads with long-running or stateful pods?**Â â†’ Isolate them on non-consolidated pools.

## Conclusion

Karpenter is powerful, but like any sharp tool, it requires tuning.

- **Empty node consolidation**Â = safe, predictable, low risk.
- **Underutilized consolidation**Â = higher savings, but requires safeguards:Â `consolidateAfter`, disruption budgets, subnet planning, and good resource discipline.

In practice, most teams start safe, then gradually roll out underutilized consolidation to a subset of workloads â€” measuring churn, restart latency, IP pressure, and cost savings before going cluster-wide.

ğŸš€ With the right strategy, Karpenter can balance bothÂ **stability and efficiency**Â â€” but the defaults are only the beginning.