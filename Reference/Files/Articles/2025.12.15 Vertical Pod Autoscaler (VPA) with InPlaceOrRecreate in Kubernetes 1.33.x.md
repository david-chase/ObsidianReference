#medium #vpa #autoscaling #k8s #ipr

## Overview

In the dynamic world of Kubernetes, defining static CPU and memory requests for workloads is often a guessing game. Set them too low, and you face performance throttling or OOMKilled errors. Set them too high, and you waste valuable infrastructure capacity.

The Vertical Pod Autoscaler (VPA) has long been the solution to this problem, automatically adjusting resource requests to “right-size” your workloads. However, until recently, applying these adjustments usually meant restarting the pods — a disruptive process for production applications.

With the release of **VPA v1.5.0** and its stabilized integration with **Kubernetes 1.33.x**, this changes fundamentally. The introduction of the `InPlaceOrRecreate` update mode allows VPA to modify resource requests on running containers dynamically, without disrupting the pod.

This post will explore how this feature works, set up a practical example, and dive deep into analyzing how VPA makes its decisions.

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:1050/1*cd_LwJ1Y5AUe-8fI7IsBMg.png)

### The Evolution of VPA Update Modes

VPA relies on three core components: the **Recommender** (analyzes historical metrics from Prometheus/Metrics Server), the **Updater** (evicts pods that need updates), and the **Admission Controller** (applies correct resources to new pods).

Traditionally, VPA managed updates using modes like `Recreate` (killing and restarting pods) or the now-deprecated `Auto` mode.

**Enter:** `InPlaceOrRecreate`

Introduced in VPA v1.5.0, the `InPlaceOrRecreate` mode is the new standard for production-ready autoscaling. It intelligently attempts to update resources with minimal disruption:

- **In-Place Update (Preferred):** If the underlying container runtime and Kubernetes API support live request updates, VPA modifies the resource requests on the running container. **Zero downtime.**
- **Recreate (Fallback):** If an in-place update isn’t possible (e.g., due to specific scheduling constraints or older cluster versions), it falls back to terminating and recreating the pod.

### The Strategy: Start Small, Scale Dynamic

This new mode enables a highly efficient cost-saving strategy: deploy workloads with very low initial resource requests and let VPA dynamically resize them up to their actual needs without restarting them.

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:1050/1*7Kh3ejriEiNf3JuQrQWi8Q.png)

### How VPA Helps with Low Initial Requests

Many workloads are deployed with **very low resource requests** (e.g., `cpu: 5m`, `memory: 64Mi`) to save costs or due to lack of data. This often leads to:

- **CPU throttling** → low performance.
- **OOMKilled errors** → insufficient memory allocation.

**Before vs After Scenario: Low Requests → VPA Adjustments  
Initial Deployment (Low Requests)**

resources:  
  requests:  
    cpu: 5m  
    memory: 64Mi  
  limits:  
    cpu: 10m  
    memory: 128Mi

**Problems:**

- Frequent throttling.
- OOMKilled errors.
- Application performance unstable.

**After VPA with** `**InPlaceOrRecreate**`

With **VPA v1.5.0** and `InPlaceOrRecreate`:

- VPA observes actual usage and increases requests dynamically.
- Pods that start with low resources are “right-sized” automatically.
- In-place updates ensure these adjustments happen with **minimal disruption**.

resources:  
  requests:  
    cpu: 250m  
    memory: 256Mi  
  limits:  
    cpu: 500m  
    memory: 512Mi

**Improvements:**

- Right-sized CPU/memory requests.
- Stable pod performance.
- In-place update prevents unnecessary restarts.

### Comparison Table

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:1050/1*3H1Zuilr1rpCD2seAo1Iqw.png)

### Hands-on Tutorial: Implementing In-Place VPA

Let’s demonstrate this capability. We will deploy a CPU-intensive application with intentionally low resource requests and watch VPA fix it in-place.

**Prerequisites**

- Kubernetes cluster version 1.33.x or later (crucial for stable in-place updates).
- VPA version 1.5.0 or later installed.

**Step 1: Installation**

If VPA is not already installed, use the official Helm chart. Ensure you enable the Admission Controller, Recommender, and Updater, pointing them to your metrics source (e.g., Prometheus).

wget https://github.com/cowboysysop/charts/releases/download/vertical-pod-autoscaler-11.1.0/vertical-pod-autoscaler-11.1.0.tgz  
tar -xvf vertical-pod-autoscaler-11.1.0.tgz  
helm upgrade --install vpa ./vertical-pod-autoscaler -n kube-system

**Step 2: Deploy the Workload and VPA**

We will create a deployment running `stress-ng` to artificially generate high CPU load. We will configure it with starved resources: only **50m CPU** and **100Mi Memory**.

We will then apply a VPA configuration with `updateMode: InPlaceOrRecreate`. We also set a **Resource Policy** to define safety guardrails (min/max allowed resources).

Create a file named `vpa-demo.yaml`:

apiVersion: apps/v1  
kind: Deployment  
metadata:  
  name: high-cpu-utilization-deployment  
  namespace: test  
spec:  
  replicas: 2  
  selector:  
    matchLabels:  
      app: cpu-utilization-app  
  template:  
    metadata:  
      labels:  
        app: cpu-utilization-app  
    spec:  
      containers:  
      - name: cpu-utilization-container  
        image: ubuntu  
        command: ["/bin/sh", "-c", "apt-get update && apt-get install -y stress-ng && while true; do stress-ng --cpu 1; done"]  
        resources:  
          # Intentionally low initial requests  
          requests:  
            cpu: "0.05" # 50m  
            memory: "100Mi"  
          limits:  
            cpu: "100m"  
            memory: "200Mi"  
---  
apiVersion: "autoscaling.k8s.io/v1"  
kind: VerticalPodAutoscaler  
metadata:  
  name: stress-vpa  
  namespace: test  
spec:  
  targetRef:  
    apiVersion: "apps/v1"  
    kind: Deployment  
    name: high-cpu-utilization-deployment  
  updatePolicy:  
    # The critical setting for in-place updates  
    updateMode: InPlaceOrRecreate  
  resourcePolicy:  
    containerPolicies:  
      - containerName: '*'  
        minAllowed:  
          cpu: 50m  
          memory: 50Mi  
        # VPA will not recommend more than these values  
        maxAllowed:  
          cpu: 200m  
          memory: 500Mi  
        controlledResources: ["cpu", "memory"]

Apply the manifest:

kubectl apply -f vpa-demo.yaml

Initially, the pods will be heavily CPU throttled. As the VPA Recommender gathers metrics, it will recognize the starvation. The Updater will then trigger an in-place update to increase the CPU request on the running containers to meet the demand, up to the defined `maxAllowed` policy.

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:1050/1*-77qTDIjO4UT-e7kmbwoFA.png)

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:1050/1*glMz_IAN4Fvp6RAYi38cIg.png)

### Analyzing VPA Behavior: Deep Dive

Understanding how VPA arrives at its recommendations is vital for production confidence. Let’s examine the status of our VPA after it has run for a while.

Run: `kubectl describe vpa stress-vpa -n test`

...  
Spec:  
  Resource Policy:  
      Max Allowed:  
        Cpu:     200m  
        Memory:  500Mi  
...  
  Update Policy:  
    Update Mode:  InPlaceOrRecreate  
Status:  
  Recommendation:  
    Container Recommendations:  
      Container Name:  cpu-utilization-container  
      Lower Bound:  
        Cpu:     200m  
        Memory:  250Mi  
      Target:  
        Cpu:     200m  
        Memory:  351198544  # ~335Mi  
      Uncapped Target:  
        Cpu:     476m  
        Memory:  351198544  # ~335Mi  
      Upper Bound:  
        Cpu:     200m  
        Memory:  500Mi

Let’s decode this output, which reveals distinct behaviors for CPU and Memory.

**The CPU Analysis: Policy Capping**

You will notice something interesting in the CPU recommendations:

- **Uncapped Target: 476m:** Based on actual usage data, the VPA’s algorithm determined the pod _wants_ 476m of CPU to run optimally.
- **Target: 200m:** However, the actual recommendation is clamped down to 200m.

**Why?** This is your `resourcePolicy` in action. You set a `maxAllowed.cpu` of `200m`. VPA respected this limit. The fact that the `Lower Bound` is also 200m indicates that even the most conservative safe estimate from the recommender was higher than your policy limit.

**Result:** Your pods will be updated in-place to 200m CPU, but they will likely remain CPU-throttled because they actually need more. To fix this, you would need to increase the `maxAllowed` CPU in the VPA spec.

**The Memory Analysis: Safety Buffering**

Memory recommendations often confuse users because they seem higher than instantaneous usage. For example, your pod might currently use 120Mi, but VPA recommends a **Target of ~335Mi**.

**Why does VPA recommend so much memory?** VPA is designed to prevent OOMKills, which kill the application entirely. Unlike CPU, memory cannot be throttled. Therefore, VPA is intentionally conservative:

1. **Historical Trends:** It looks at long-term data (days), not just the last 5 minutes. If the pod spiked to 300Mi yesterday, VPA remembers.
2. **Smoothing & Percentiles:** VPA aims for high percentiles (e.g., 95th percentile of usage) and adds a safety margin to ensure enough headroom for sudden spikes.

**Result:** The memory recommendation of ~335Mi is within your policy limits (50Mi — 500Mi), so VPA will apply this target to ensure stability.

After the recommendation, without any pod restart or recreation, the existing pods automatically received the new recommended values, and any newly launched pods also started with the updated values.

### Benefits of InPlaceOrRecreate

1. **Reduced Downtime** — Adjust requests without restarts (if supported).
2. **Smarter Updates** — Automatically falls back to recreate only when necessary.
3. **Right-Sizing** — Fixes workloads with **low initial requests** by adjusting dynamically.
4. **Cost Efficiency** — Avoids overprovisioning while preventing under-provisioning.

### Best Practices

- Start with **Initial** in production, then move to `InPlaceOrRecreate`.
- Always monitor recommendations before enabling auto-updates.
- Deploy workloads with **safe minimums**; let VPA optimize them.

### Management and Troubleshooting Strategies

Managing VPA in production requires a few key tactics.

**1. Essential Diagnostic Commands**

When VPA isn’t behaving as expected, gather data in this order:

# 1. Check the VPA config and current recommendations  
kubectl describe vpa stress-vpa -n test  
# 2. Check the target pod's current requests vs actual usage  
kubectl describe pod <your-pod-name> -n test  
kubectl top pod <your-pod-name> -n test  
# 3. Check VPA logs for errors (adjust namespace if needed)  
kubectl -n kube-system logs deployment/vpa-recommender  
kubectl -n kube-system logs deployment/vpa-updater  
# 4. Look for OOMKills or recent events  
kubectl get events -n test --sort-by=.lastTimestamp | tail -n 50

**2. Safe Operations Strategy**

Before turning on automated updates in production:

- **Start in “Off” Mode:** Set `updateMode: "Off"`. Let VPA run for at least 24 hours to gather data and generate recommendations without applying them. Compare these recommendations against your current settings.
- **Use Pod Disruption Budgets (PDB):** Even with in-place updates, fallback recreation might occur. Always ensure a PDB is active for your deployment to prevent VPA from taking down too many replicas simultaneously.
- **Resetting History:** If you make a radical change to your application and past historical metrics are no longer relevant, you can force VPA to re-learn by deleting and recreating the VPA object.

kubectl delete vpa stress-vpa -n test  
kubectl apply -f vpa-demo.yaml

## Conclusion

With VPA v1.5.0 running on Kubernetes 1.33.x, the `InPlaceOrRecreate` mode offers the optimal balance of stability and cost-efficiency. It allows operations teams to move away from static, padded resource estimates and toward a dynamic infrastructure that adjusts to actual workload demands without constant disruptions.

By starting workloads with minimal requests and allowing VPA to handle the vertical scaling in-place, you can achieve significant infrastructure savings while ensuring application performance.

This results in:

- **Stable applications** (no more OOMKills or throttling).
- **Better resource utilization** across the cluster.
- **Minimal downtime** with in-place adjustments.
- **Future-ready scaling** aligned with Kubernetes 1.33+.